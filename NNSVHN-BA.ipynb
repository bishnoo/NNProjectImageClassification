{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bananth\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SVHN_single_grey1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(filename,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: KeysView(<HDF5 file \"SVHN_single_grey1.h5\" (mode r)>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys: %s\" % f.keys())\n",
    "a_group_key = list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_group_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = f['X_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = f['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = f['X_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = f['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = f['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = f['y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"X_test\": shape (18000, 32, 32), type \"<f4\">\n",
      "(18000, 32, 32)\n",
      "<HDF5 dataset \"X_train\": shape (42000, 32, 32), type \"<f4\">\n",
      "(42000, 32, 32)\n",
      "<HDF5 dataset \"X_val\": shape (60000, 32, 32), type \"<f4\">\n",
      "(60000, 32, 32)\n",
      "<HDF5 dataset \"y_test\": shape (18000,), type \"|u1\">\n",
      "(18000,)\n",
      "<HDF5 dataset \"y_train\": shape (42000,), type \"|u1\">\n",
      "(42000,)\n",
      "<HDF5 dataset \"y_val\": shape (60000,), type \"|u1\">\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "for key in f:\n",
    "    d = f[key]\n",
    "    print(d)\n",
    "    print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 33.0704,  30.2601,  26.852 , ...,  71.4471,  58.2204,  42.9939],\n",
       "       [ 25.2283,  25.5533,  29.9765, ..., 113.0209, 103.3639,  84.2949],\n",
       "       [ 26.2775,  22.6137,  40.4763, ..., 113.3028, 121.775 , 115.4228],\n",
       "       ...,\n",
       "       [ 28.5502,  36.212 ,  45.0801, ...,  24.1359,  25.0927,  26.0603],\n",
       "       [ 38.4352,  26.4733,  23.2717, ...,  28.1094,  29.4683,  30.0661],\n",
       "       [ 50.2984,  26.0773,  24.0389, ...,  49.6682,  50.853 ,  53.0377]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 32, 32)\n",
      "(18000, 32, 32)\n",
      "(60000, 32, 32)\n",
      "(42000,)\n",
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train.shape\n",
    "n1samples,n1x,n1y = X_test.shape\n",
    "n2samples,n2x,n2y = X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train.value.reshape((nsamples,nx*ny))\n",
    "X_test_new = X_test.value.reshape((n1samples,n1x*n1y))\n",
    "X_val_new = X_val.value.reshape((n2samples,n2x*n2y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n",
      "(60000, 1024)\n",
      "(42000,)\n",
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_new.shape)\n",
    "print(X_test_new.shape)\n",
    "print(X_val_new.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_5 = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_5.fit(X_train_new,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_knn_5 = knn_5.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"KNN ACCURACY for 5 Neighbors:\",metrics.accuracy_score(y_test,y_pred_class_knn_5))\n",
    "print('KNN CLASSIFIER CONFUSTION MATRIX - 5 Neighbors:',pd.crosstab(y_test,y_pred_class_knn_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score  0.49 \n",
      "F1 score is  0.49\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.66      0.48      1814\n",
      "          1       0.44      0.70      0.54      1828\n",
      "          2       0.55      0.52      0.53      1803\n",
      "          3       0.42      0.39      0.41      1719\n",
      "          4       0.67      0.61      0.64      1812\n",
      "          5       0.48      0.36      0.41      1768\n",
      "          6       0.47      0.38      0.42      1832\n",
      "          7       0.72      0.58      0.64      1808\n",
      "          8       0.42      0.33      0.37      1812\n",
      "          9       0.52      0.36      0.43      1804\n",
      "\n",
      "avg / total       0.51      0.49      0.49     18000\n",
      "\n",
      "Confusion matrix \n",
      "[[1201   60   44   37   45   45  129   31  109  113]\n",
      " [ 125 1285   83   81   84   36   36   58   18   22]\n",
      " [ 126  252  932  115   44   44   28  128   69   65]\n",
      " [ 164  255  166  677   54  157   36   46   92   72]\n",
      " [ 148  256   47   61 1101   30   64   17   48   40]\n",
      " [ 196  179   91  261   43  637  130   31  114   86]\n",
      " [ 370  120   50   70  116  154  695   16  188   53]\n",
      " [ 135  254  138   78   23   26   26 1045   28   55]\n",
      " [ 330  140   71  118   84  109  256   20  592   92]\n",
      " [ 382  145   83  106   51   89   86   61  143  658]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score %5.2f \" %(accuracy_score(y_true=y_test, y_pred=y_pred_class_knn_5)))\n",
    "print(\"F1 score is %5.2f\" %(f1_score(y_true=y_test, y_pred=y_pred_class_knn_5, average='weighted')))\n",
    "print(\"Classification report\")\n",
    "print(classification_report(y_test, y_pred_class_knn_5))\n",
    "print(\"Confusion matrix \")\n",
    "print(confusion_matrix(y_test, y_pred_class_knn_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us normalize the data\n",
    "X_train_new = X_train_new/1024\n",
    "X_test_new = X_test_new/1024\n",
    "X_val_new = X_val_new/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n",
      "(60000, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_new.shape)\n",
    "print(X_test_new.shape)\n",
    "print(X_val_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us convert Y values to categorical\n",
    "y_train_new = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us create a model\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x1c5409f7358>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add batch normalization\n",
    "#model.add(tf.keras.layers.BatchNormalization())\n",
    "#Add a dense layer with 200 neurons\n",
    "tf.keras.layers.Dense(units=200, activation='relu', input_shape=(1024,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us add few more layers with units=100, 50, 20 and output layer with unit as 10\n",
    "model.add(tf.keras.layers.Dense(units=150, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(units=70, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(units=30, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',precision,recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/30\n",
      "42000/42000 [==============================] - 10s 230us/step - loss: 2.3039 - acc: 0.1005 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3028 - val_acc: 0.1000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/30\n",
      "42000/42000 [==============================] - 7s 177us/step - loss: 2.2727 - acc: 0.1240 - precision: 0.1676 - recall: 0.0044 - val_loss: 2.1571 - val_acc: 0.1761 - val_precision: 0.1013 - val_recall: 0.0162\n",
      "Epoch 3/30\n",
      "42000/42000 [==============================] - 7s 176us/step - loss: 2.0692 - acc: 0.2117 - precision: 0.6555 - recall: 0.0323 - val_loss: 1.9970 - val_acc: 0.2386 - val_precision: 0.1231 - val_recall: 0.0338\n",
      "Epoch 4/30\n",
      "42000/42000 [==============================] - 7s 173us/step - loss: 1.9636 - acc: 0.2499 - precision: 0.6860 - recall: 0.0427 - val_loss: 1.9454 - val_acc: 0.2517 - val_precision: 0.2038 - val_recall: 0.0412\n",
      "Epoch 5/30\n",
      "42000/42000 [==============================] - 7s 167us/step - loss: 1.9203 - acc: 0.2666 - precision: 0.6485 - recall: 0.0503 - val_loss: 1.8806 - val_acc: 0.2780 - val_precision: 0.2152 - val_recall: 0.0581\n",
      "Epoch 6/30\n",
      "42000/42000 [==============================] - 8s 189us/step - loss: 1.8910 - acc: 0.2765 - precision: 0.6340 - recall: 0.0542 - val_loss: 1.8661 - val_acc: 0.2863 - val_precision: 0.2337 - val_recall: 0.0576\n",
      "Epoch 7/30\n",
      "42000/42000 [==============================] - 8s 181us/step - loss: 1.8647 - acc: 0.2894 - precision: 0.6333 - recall: 0.0623 - val_loss: 1.8588 - val_acc: 0.2928 - val_precision: 0.3360 - val_recall: 0.0581\n",
      "Epoch 8/30\n",
      "42000/42000 [==============================] - 7s 178us/step - loss: 1.8238 - acc: 0.3106 - precision: 0.6477 - recall: 0.0742 - val_loss: 1.8069 - val_acc: 0.3179 - val_precision: 0.4632 - val_recall: 0.0751\n",
      "Epoch 9/30\n",
      "42000/42000 [==============================] - 8s 179us/step - loss: 1.7804 - acc: 0.3310 - precision: 0.6515 - recall: 0.0888 - val_loss: 1.7375 - val_acc: 0.3580 - val_precision: 0.5241 - val_recall: 0.0917\n",
      "Epoch 10/30\n",
      "42000/42000 [==============================] - 7s 176us/step - loss: 1.7366 - acc: 0.3588 - precision: 0.6614 - recall: 0.1036 - val_loss: 1.7227 - val_acc: 0.3711 - val_precision: 0.5145 - val_recall: 0.1141\n",
      "Epoch 11/30\n",
      "42000/42000 [==============================] - 7s 174us/step - loss: 1.6751 - acc: 0.3987 - precision: 0.6658 - recall: 0.1211 - val_loss: 1.6950 - val_acc: 0.3859 - val_precision: 0.5553 - val_recall: 0.1218\n",
      "Epoch 12/30\n",
      "42000/42000 [==============================] - 7s 173us/step - loss: 1.6118 - acc: 0.4316 - precision: 0.6691 - recall: 0.1573 - val_loss: 1.5896 - val_acc: 0.4449 - val_precision: 0.6164 - val_recall: 0.1666\n",
      "Epoch 13/30\n",
      "42000/42000 [==============================] - 7s 178us/step - loss: 1.5761 - acc: 0.4494 - precision: 0.6840 - recall: 0.1838 - val_loss: 1.5441 - val_acc: 0.4651 - val_precision: 0.6248 - val_recall: 0.2040\n",
      "Epoch 14/30\n",
      "42000/42000 [==============================] - 7s 176us/step - loss: 1.5609 - acc: 0.4586 - precision: 0.6802 - recall: 0.1999 - val_loss: 1.5991 - val_acc: 0.4395 - val_precision: 0.6256 - val_recall: 0.1999\n",
      "Epoch 15/30\n",
      "42000/42000 [==============================] - 7s 174us/step - loss: 1.5389 - acc: 0.4674 - precision: 0.6885 - recall: 0.2175 - val_loss: 1.5128 - val_acc: 0.4804 - val_precision: 0.6558 - val_recall: 0.2266\n",
      "Epoch 16/30\n",
      "42000/42000 [==============================] - 7s 173us/step - loss: 1.5215 - acc: 0.4747 - precision: 0.6945 - recall: 0.2338 - val_loss: 1.5441 - val_acc: 0.4711 - val_precision: 0.6696 - val_recall: 0.2451\n",
      "Epoch 17/30\n",
      "42000/42000 [==============================] - 7s 172us/step - loss: 1.4940 - acc: 0.4873 - precision: 0.7005 - recall: 0.2604 - val_loss: 1.4709 - val_acc: 0.4996 - val_precision: 0.6917 - val_recall: 0.2683\n",
      "Epoch 18/30\n",
      "42000/42000 [==============================] - 7s 173us/step - loss: 1.4719 - acc: 0.4986 - precision: 0.7056 - recall: 0.2803 - val_loss: 1.4500 - val_acc: 0.5079 - val_precision: 0.6898 - val_recall: 0.2939\n",
      "Epoch 19/30\n",
      "42000/42000 [==============================] - 7s 174us/step - loss: 1.4334 - acc: 0.5138 - precision: 0.7139 - recall: 0.3078 - val_loss: 1.3868 - val_acc: 0.5328 - val_precision: 0.7231 - val_recall: 0.3293\n",
      "Epoch 20/30\n",
      "42000/42000 [==============================] - 7s 170us/step - loss: 1.3882 - acc: 0.5306 - precision: 0.7220 - recall: 0.3411 - val_loss: 1.3631 - val_acc: 0.5402 - val_precision: 0.7094 - val_recall: 0.3590\n",
      "Epoch 21/30\n",
      "42000/42000 [==============================] - 7s 171us/step - loss: 1.3514 - acc: 0.5452 - precision: 0.7272 - recall: 0.3688 - val_loss: 1.3412 - val_acc: 0.5528 - val_precision: 0.7189 - val_recall: 0.3803\n",
      "Epoch 22/30\n",
      "42000/42000 [==============================] - 8s 185us/step - loss: 1.3242 - acc: 0.5574 - precision: 0.7326 - recall: 0.3930 - val_loss: 1.3149 - val_acc: 0.5624 - val_precision: 0.7369 - val_recall: 0.3928\n",
      "Epoch 23/30\n",
      "42000/42000 [==============================] - 8s 180us/step - loss: 1.3051 - acc: 0.5642 - precision: 0.7404 - recall: 0.4060 - val_loss: 1.2620 - val_acc: 0.5833 - val_precision: 0.7458 - val_recall: 0.4225\n",
      "Epoch 24/30\n",
      "42000/42000 [==============================] - 7s 171us/step - loss: 1.2916 - acc: 0.5695 - precision: 0.7409 - recall: 0.4156 - val_loss: 1.2783 - val_acc: 0.5757 - val_precision: 0.7402 - val_recall: 0.4199\n",
      "Epoch 25/30\n",
      "42000/42000 [==============================] - 7s 175us/step - loss: 1.2751 - acc: 0.5787 - precision: 0.7462 - recall: 0.4250 - val_loss: 1.3025 - val_acc: 0.5632 - val_precision: 0.7219 - val_recall: 0.4182\n",
      "Epoch 26/30\n",
      "42000/42000 [==============================] - 7s 174us/step - loss: 1.2692 - acc: 0.5773 - precision: 0.7496 - recall: 0.4282 - val_loss: 1.2393 - val_acc: 0.5934 - val_precision: 0.7602 - val_recall: 0.4373\n",
      "Epoch 27/30\n",
      "42000/42000 [==============================] - 7s 177us/step - loss: 1.2553 - acc: 0.5836 - precision: 0.7529 - recall: 0.4366 - val_loss: 1.2585 - val_acc: 0.5818 - val_precision: 0.7392 - val_recall: 0.4385\n",
      "Epoch 28/30\n",
      "42000/42000 [==============================] - 7s 175us/step - loss: 1.2512 - acc: 0.5882 - precision: 0.7570 - recall: 0.4385 - val_loss: 1.2476 - val_acc: 0.5887 - val_precision: 0.7531 - val_recall: 0.4401\n",
      "Epoch 29/30\n",
      "42000/42000 [==============================] - 7s 172us/step - loss: 1.2408 - acc: 0.5929 - precision: 0.7578 - recall: 0.4455 - val_loss: 1.2275 - val_acc: 0.5951 - val_precision: 0.7598 - val_recall: 0.4472\n",
      "Epoch 30/30\n",
      "42000/42000 [==============================] - 7s 173us/step - loss: 1.2441 - acc: 0.5899 - precision: 0.7598 - recall: 0.4453 - val_loss: 1.2091 - val_acc: 0.6046 - val_precision: 0.7652 - val_recall: 0.4562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c5409d72e8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the data and execute the model\n",
    "model.fit(x=X_train_new, y=y_train_new, batch_size=64, epochs=30, validation_data=(X_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 77us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.21189995320638, 0.6026111111111111, 0.7751187131669787, 0.45422222222222225]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_new, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "    KNN was much slower for k value =5.\n",
    "    Neural networks, without much of tuning still managed to get good accuracy along with high accuracy\n",
    "    Printed Recall & Precision also while running the model. with 75% and 45% Recall for the Testing Accuracy as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
